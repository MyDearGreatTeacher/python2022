
```
Chapter 01 環境設定與網頁爬蟲初探
1-1 環境設定及套件安裝：Anaconda
1-2 使用IDE：PyCharm
1-3 使用Jupyter Notebook
1-4 網頁文件解構與網頁爬蟲初探

Chapter 02 Beautiful Soup 講解與網頁解構
2-1 不要重複造輪子：寫爬蟲之前
2-2 Beautiful Soup 重要功能 (find(), find_all(), .text, .stripped_strings)
2-3 網頁結構巡覽（parent, children, siblings）
2-4 正規表示式 (Regular Expression)

Chapter 03 網頁爬蟲範例實戰
3-1 PTT 八卦板今日熱門文章
3-2 Yahoo 奇摩電影本週新片
3-3 兩大報當日焦點新聞
3-4 Google 搜尋股價資訊
3-5 Dcard 今日熱門文章

Chapter 04 使用 API
4-1 API 簡介
4-2 PTT 八卦板眾來源分佈 (ipstack.com)
4-3 IMDB API
4-4 Google Maps APIs (Google Geocoding/Places API)
4-5 Dcard API

Chapter0 5 資料儲存
5-1 儲存圖片與多媒體檔案
5-2 儲存資料到 CSV 檔
5-3 儲存資料到資料庫 SQLite

Chapter 06 不同編碼與類型的文件
6-1 非 UTF-8 編碼的文件
6-2 XML 文件

Chapter 07 進階爬蟲議題
7-1 處理表單及登入頁 ：台灣高鐵時刻查詢
7-2 處理表單及登入頁 ：Yelp 登入
7-3 使用WebDriver：台銀法拍屋資訊查詢
7-4 爬蟲程式經驗談：被封鎖的常見原因、常用 Header 欄位、網站隱藏欄位、使用代理伺服器

Chapter 08 資料分析實戰
8-1 台股每日盤後資訊爬蟲及策略回測（量化投資）
8-2 電影評論情緒分析（中文自然語言處理與機器學習）
8-3 商品特價 Gmail 通知：Costco 商品網頁

附表 本書範例目標網站列表

附錄A 在 Mac 安裝Anaconda 開發環境

附錄B Python 爬蟲框架Scrapy 入門教學
B-1 Scrapy 環境安裝
B-2 簡易部落格爬蟲
B-3 Scrapy 系統架構
```
